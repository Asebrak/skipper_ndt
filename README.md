# ğŸ” Skipper NDT x HETIC â€” Identification de Pipes par ML

## Structure du projet

```
skipper_project/
â”œâ”€â”€ 01_explore_data.py   # Ã‰TAPE 1 : Exploration et visualisation des donnÃ©es
â”œâ”€â”€ dataset.py           # Ã‰TAPE 2 : Dataset PyTorch + preprocessing
â”œâ”€â”€ models.py            # Ã‰TAPE 3 : Architectures CNN (scratch & ResNet)
â”œâ”€â”€ train.py             # Ã‰TAPE 4 : EntraÃ®nement des 4 tÃ¢ches
â”œâ”€â”€ inference.py         # Ã‰TAPE 5 : InfÃ©rence (script obligatoire Skipper)
â”œâ”€â”€ plot_results.py      # Ã‰TAPE 6 : Visualisation des rÃ©sultats
â”œâ”€â”€ models/              # ModÃ¨les sauvegardÃ©s aprÃ¨s entraÃ®nement
â”‚   â”œâ”€â”€ task1/best_model.pth
â”‚   â”œâ”€â”€ task2/best_model.pth
â”‚   â”œâ”€â”€ task3/best_model.pth
â”‚   â””â”€â”€ task4/best_model.pth
â””â”€â”€ exploration_outputs/ # Graphiques gÃ©nÃ©rÃ©s
```

---

## ğŸ“¦ Installation

```bash
pip install torch torchvision numpy pandas scikit-learn matplotlib seaborn opencv-python tqdm
```

> **Mac avec Apple Silicon (M1/M2/M3)** : PyTorch supporte MPS nativement, l'entraÃ®nement sera accÃ©lÃ©rÃ© automatiquement.

---

## ğŸš€ Workflow Ã©tape par Ã©tape

### 1. Placer les fichiers de donnÃ©es

```
Training_database_float16/   â† dossier avec les 2833 fichiers .npz
pipe_detection_label.csv     â† fichier CSV de labels
skipper_project/             â† ce dossier
```

### 2. Explorer les donnÃ©es

```bash
cd chemin/vers/dossier/contenant/Training_database_float16/
python skipper_project/01_explore_data.py
```
â†’ GÃ©nÃ¨re des visualisations dans `exploration_outputs/`

### 3. EntraÃ®ner les modÃ¨les

```bash
# TÃ¢che 1 : PrÃ©sence de conduite (binaire)
python skipper_project/train.py --task task1 --arch resnet18 --epochs 30

# TÃ¢che 2 : Largeur magnÃ©tique (rÃ©gression)
python skipper_project/train.py --task task2 --arch resnet18 --epochs 40

# TÃ¢che 3 : IntensitÃ© du courant (binaire)
python skipper_project/train.py --task task3 --arch resnet18 --epochs 25

# TÃ¢che 4 : Conduites parallÃ¨les (binaire, dataset plus petit)
python skipper_project/train.py --task task4 --arch resnet18 --epochs 35 --dropout 0.5
```

> **Astuce** : Pour des tests rapides, utiliser `--arch scratch` (pas de tÃ©lÃ©chargement de poids).

### 4. InfÃ©rence (livrable obligatoire)

```bash
# Sur un fichier unique â€” toutes les tÃ¢ches
python skipper_project/inference.py --all --input sample_00000_perfect_straight_clean_field.npz

# Sur une tÃ¢che spÃ©cifique
python skipper_project/inference.py --task task1 --input sample_00000.npz

# Sur un dossier entier â†’ export CSV
python skipper_project/inference.py --all --input_dir Training_database_float16/ --output predictions.csv
```

### 5. Visualiser les rÃ©sultats

```bash
python skipper_project/plot_results.py
```

---

## ğŸ¯ Objectifs par tÃ¢che

| TÃ¢che | Type | Objectif | MÃ©trique |
|-------|------|----------|---------|
| T1 : PrÃ©sence de conduite | Classification | Accuracy > 92%, Recall > 95% | CrossEntropy |
| T2 : Largeur magnÃ©tique | RÃ©gression | MAE < 1m | SmoothL1 |
| T3 : IntensitÃ© courant | Classification | Accuracy > 90%, Recall > 85% | CrossEntropy |
| T4 : Conduites parallÃ¨les | Classification | F1 > 0.80 | CrossEntropy |

---

## ğŸ“ Livrables Ã  soumettre

Pour chaque tÃ¢che, crÃ©er un dossier :

```
task1/
â”œâ”€â”€ best_model.pth   â† modÃ¨le PyTorch entraÃ®nÃ©
â”œâ”€â”€ train.py         â† script d'entraÃ®nement (optionnel)
â””â”€â”€ inference.py     â† script d'infÃ©rence (OBLIGATOIRE)
```

**Usage de inference.py (attendu par Skipper) :**
```bash
python inference.py --task task1 --input chemin/vers/image.npz
```

---

## ğŸ’¡ Notes techniques

### Format des fichiers NPZ
- Chaque fichier contient les 4 canaux magnÃ©tiques : **Bx, By, Bz, Norm**
- UnitÃ© : nanoTesla (nT)
- Dimensions variables : 150Ã—150 Ã  4000Ã—3750 pixels
- 1 pixel = 0.2m Ã— 0.2m

### Preprocessing
- **Padding + Resize** vers 224Ã—224 (prÃ©serve les ratios)
- **Normalisation** par canal (Î¼=0, Ïƒ=1)
- **Augmentation** : flip H/V, rotation 90Â°, bruit gaussien

### Architecture
- **ResNet18 adaptÃ© 4 canaux** : 1Ã¨re couche modifiÃ©e pour accepter 4 canaux
- **Global Average Pooling** : invariant Ã  la taille d'entrÃ©e
- **Transfer Learning** depuis ImageNet + fine-tuning complet

### Labels utilisÃ©s
- T1 : colonne `label` (0=absent, 1=prÃ©sent)
- T2 : colonne `width_m` (flottant, 2-155m)
- T3 : colonne `coverage_type` ("perfect"=1, autres=0)
- T4 : colonne `pipe_type` ("parallel"=1, "single"=0)
